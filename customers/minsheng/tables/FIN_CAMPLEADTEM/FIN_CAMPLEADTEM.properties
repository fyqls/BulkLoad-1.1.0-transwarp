# Test module
#test_tableName=CDR_SMS_TEST
#test_inputDir=hdfs://monkey:8020/tmp/monkey-test/sms_test
#test_outputDir=hdfs://monkey:8020/tmp/hfile/sms_test
#test_indextablename=CDR_SMS_idx_test


# The hbase table name
tableName=FIN_CAMPLEADTEM
# The input directory on hdfs
#inputDir=hdfs://transwarp03:8020/tmp/monkey-test/sms
inputDir=/import_data/sadata/FIN_CAMPLEADTEM
# The test input directory on hdfs
# The output hfile address, the same parameter with the secondary index loading
outputDir=/import_data/sadata/FIN_CAMPLEADTEM_OUTPUT

# MapReduce input format, default is Text
# Text		: For the general text file
# CombineFile	: For the combine file input format
# MultiHFile	: For the multi hfile input format 
inputFormat=Text
#inputFormat=MultiHFile
#inputFormat=CombineFile

# ======== Text File ===================
# The following parameters are just used for TextInputFormat,
# you can comment them when you don't use the TextInfputFormat
mapred_min_split_size=1

# ======= Combine File ==================
# The following two parameters are just used for CombineFile,
# you can comment them when you don't use the CombineFile
# Input split size for single mapper
splitSize=67108864
# If you want to load the file from other hdfs system
isRemote=false

# ========= Multi HFile ====================
# The following parameters are used for MultiHFile,
# you can comment them when you don't use the MultiHFile
# The hbase index table name
# Uset the indextablename as the switch of the secondary index bulk load
#indextablename=CDR_SMS_idx
# The indexed columns
#indexcolumns=e:f
# The indexed table column family
#targetcolumnfamily=f
# The start row
#startrow=
# The stop row
#stoprow=
# The output hfile address for the index table, recently it is useless
#indexOutputDir=hdfs://monkey:8020/tmp/hfile/sms_idx
# The split key of the index table
#indexSplitKeySpec=00,99
# Whether just insert the secondary index from existed hfiles or 
# insert the secondary index with the insertion of hfiles

 

# How the input file is formated
textRecordSpec=CLTID,CAMID,LEAID,CLTNAME,TARGETSTYPE,CONTACTGROUPID,CONTACTGROUPSQL,EVALUATIONPROGRAMID,EXECUTEDATE,LASTEXECUTETIME,STARTDATE,ENDDATE,CHANNELTYPE,RECCREATEUID,RECCREATEDATE,RECUPDDATE,STATUS,MEMO,OWERORGID,EVALUATIONEXECUTEDATE,CONPRISOLID,EXECROLES,SERVICEITEMID,MANSTART,ACTYHID,DELAYTYPE,DELAYCODE,SOPQUEGUID,SOPDELAYTYPE,SOPDELAYCODE,WORKFLAG,END
#encoding of the input text file. default UTF-8 if otherwise specified
encoding=UTF-8
# Fields delimiter in input file,default "," if not specified
fieldDelimiter=,

# HBase row specification
# The internal filed dielimiter in the hbase table, such as the rowkey c1~c2
rowSpec=rowKey:trim(CLTID);f1|EXECUTEDATE:trim(EXECUTEDATE);f|CAMID:trim(CAMID);f|LEAID:trim(LEAID);f|CLTNAME:trim(CLTNAME);f|TARGETSTYPE:trim(TARGETSTYPE);f|CONTACTGROUPID:trim(CONTACTGROUPID);f|CONTACTGROUPSQL:trim(CONTACTGROUPSQL);f|EVALUATIONPROGRAMID:trim(EVALUATIONPROGRAMID);f|LASTEXECUTETIME:trim(LASTEXECUTETIME);f|STARTDATE:trim(STARTDATE);f|ENDDATE:trim(ENDDATE);f|CHANNELTYPE:trim(CHANNELTYPE);f|RECCREATEUID:trim(RECCREATEUID);f|RECCREATEDATE:trim(RECCREATEDATE);f|RECUPDDATE:trim(RECUPDDATE);f|STATUS:trim(STATUS);f|MEMO:trim(MEMO);f|OWERORGID:trim(OWERORGID);f|EVALUATIONEXECUTEDATE:trim(EVALUATIONEXECUTEDATE);f|CONPRISOLID:trim(CONPRISOLID);f|EXECROLES:trim(EXECROLES);f|SERVICEITEMID:trim(SERVICEITEMID);f|MANSTART:trim(MANSTART);f|ACTYHID:trim(ACTYHID);f|DELAYTYPE:trim(DELAYTYPE);f|DELAYCODE:trim(DELAYCODE);f|SOPQUEGUID:trim(SOPQUEGUID);f|SOPDELAYTYPE:trim(SOPDELAYTYPE);f|SOPDELAYCODE:trim(SOPDELAYCODE);f|WORKFLAG:trim(WORKFLAG)
internalFieldDelimiter=~
# Split key spec generated using RegionSplitKeyUtils.java
splitKeySpec=1535,2038,760
